{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Background:\n",
    "\n",
    "## Risksmart and its contemporary GRACE capture event related information among other data points such as controls, change initiatives etc. This unexplored repository provides a rich source of data that augments (and often precedes) remediation related information.​\n",
    "## Remediation Analytics and Remediation Portfolio Management are working closely to best utilise Risksmart/GRACE data in order to:​\n",
    "## Build an automated capability to flag remediation related events, creating efficiencies and reducing risk.​\n",
    "## Help with sequencing and prioritisation of remediation events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import url\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlwings as xw\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "import os, sys\n",
    "import win32com.client\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "import warnings\n",
    "import xlwings as xw\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# %%timeit\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.width', 2000)\n",
    "pd.options.display.max_colwidth = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\XXXX'\n",
    "file = 'Risksmart data 2014 to current.xlsx'\n",
    "\n",
    "# load data into dataframe\n",
    "df = pd.read_excel(path + file, sheetname= 'Sheet2', index_col=None)\n",
    "\n",
    "df1 = df[['EVENT_ID','TITLE','DESCRIPTION','NFI_REMEDIATION_RATING']].drop_duplicates()\n",
    "df1 = df1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from collections import Counter\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def bag_of_words(sentence):\n",
    "    # remove punctuation marks\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    sentence = sentence.translate(translator)\n",
    "    \n",
    "    # remove numeric:\n",
    "    sentence = ''.join([i for i in sentence if not i.isdigit()]) \n",
    "    \n",
    "    # tokenize the words in event description\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(sentence.lower())\n",
    "\n",
    "    # remove stop words\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    tokens2 = [x for x in tokens if x not in stopwords]\n",
    "    bag_of_words = Counter(tokens2)\n",
    "    return dict(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Insignificant    12931\n",
       "Minor             2608\n",
       "Moderate           519\n",
       "Major               35\n",
       "Critical             5\n",
       "Name: NFI_REMEDIATION_RATING, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['NFI_REMEDIATION_RATING'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenization - occurrence of words and number of frequency\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "df_freq=pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(df2)):\n",
    "    bag = bag_of_words(df2.loc[i].DESCRIPTION)\n",
    "    bag.update( {'EVENT_ID' : df2.loc[i].EVENT_ID})\n",
    "    bag.update( {'NFI_REMEDIATION_RATING' : df2.loc[i].NFI_REMEDIATION_RATING})\n",
    "    df_freq = df_freq.append([bag])\n",
    "\n",
    "## specifying filters - key identifiers \n",
    "filters = {'remediation':not None, 'refund':not None, 'impact':not None}\n",
    "pd.Series(filters)\n",
    "\n",
    "df_freq[list(filters)] == pd.Series(filters)\n",
    "(df_freq[list(filters)] == pd.Series(filters)).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered=pd.DataFrame()\n",
    "filtered = filtered.append(df_freq.loc[(df_freq[list(filters)] == pd.Series(filters)).any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>NFI_REMEDIATION_RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35802911</td>\n",
       "      <td>Critical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79945708</td>\n",
       "      <td>Critical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EVENT_ID NFI_REMEDIATION_RATING\n",
       "0  35802911               Critical\n",
       "0  79945708               Critical"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered[['EVENT_ID','NFI_REMEDIATION_RATING']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## training the predicted model using Random forest\n",
    "\n",
    "\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5 = df5.fillna(0)\n",
    "\n",
    "def casewhen(row):\n",
    "    if row['NFI_REMEDIATION_RATING'] == 'Critical':\n",
    "        return 1\n",
    "    elif row['NFI_REMEDIATION_RATING'] =='Major':\n",
    "        return 2\n",
    "    elif row['NFI_REMEDIATION_RATING'] =='Moderate':\n",
    "        return 3\n",
    "    elif row['NFI_REMEDIATION_RATING'] =='Minor':\n",
    "        return 4\n",
    "    elif row['NFI_REMEDIATION_RATING'] =='Insignificant':\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "df5['RATING'] = df5.apply(casewhen, axis=1)\n",
    "\n",
    "\n",
    "# Create a list of the feature column's names\n",
    "features = df5.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df5[features] , df5['RATING'] ,random_state = 1)\n",
    "\n",
    "df5['is_train'] = np.random.uniform(0, 1, len(df5)) <= .75\n",
    "train, test = df5[df5['is_train']==True], df5[df5['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = train[features]\n",
    "\n",
    "X_test = test[features]\n",
    "\n",
    "# y_train = pd.factorize(train['NFI_REMEDIATION_RATING'])[0]\n",
    "\n",
    "y_train = np.array(train['RATING'])\n",
    "\n",
    "# y_test = pd.factorize(test['NFI_REMEDIATION_RATING'])[0]\n",
    "\n",
    "y_test = np.array(test['RATING'])\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, preds, rownames=['Actual'], colnames=['Predicted'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
