{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing using windowing functions\n",
    "\n",
    "\n",
    " * To do quarterly event reporting comparing events between different systems (from holocron export and data extract from other repository) - handling input data stored in hdfs in terms of dataframes\n",
    " \n",
    " * Usage of windowing functions to estimate refund amount and overall impact of the events \n",
    " * Usage of partitions and usage of aggregation, ranking and analytical functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    appName('event_reporting'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()\n",
    "\n",
    "spark.conf.set('spark.sql.shuffle.partitions', '2')\n",
    "\n",
    "events_hc = spark.read. \\\n",
    "    option(\"inferSchema\", \"false\").\n",
    "    schema(\"\"\"event_id INT, event_date TIMESTAMP,\n",
    "              event_reference_id INT, event_status STRING\n",
    "           \"\"\").\n",
    "    format(\"json\").\n",
    "    load(\"filepath/file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, count, lpad, concat\n",
    "from pyspark.sql.functions import min, max, sum, avg\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, dense_rank, lead\n",
    "from pyspark.sql.functions import percent_rank, row_number, round\n",
    "\n",
    "events_path = \"/events data from hdfs\"\n",
    "\n",
    "events_mdr = spark. \\\n",
    "    read. \\\n",
    "    parquet(events_path)\n",
    "\n",
    "events_hc = spark. \\\n",
    "    read. \\\n",
    "    option(\"inferSchema\", \"false\"). \\\n",
    "    schema(\"\"\"event_id INT, event_date TIMESTAMP,\n",
    "              event_reference_id INT, event_status STRING\n",
    "           \"\"\").\n",
    "    format(\"json\"). \\\n",
    "    load(\"filepath/file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_hc. \\\n",
    "    join(events_mdr, events_hc.event_reference_id == events_mdr[\"Origin\"]). \\\n",
    "    select(\"Year\", \"Month\", \"DayOfMonth\", events_mdr[\"*\"], \"RefundAmount\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_count_per_audit_date = \n",
    "    events_hc. \\\n",
    "    join(events_mdr, events_hc.event_reference_id == events_mdr[\"Origin\"]). \\\n",
    "    #select(\"Year\", \"Month\", \"DayOfMonth\", events_mdr[\"*\"], \"RefundAmount\"). \\\n",
    "    groupBy(\"Origin\"). \\\n",
    "    agg(count(lit(1)).alias(\"Event_count\")). \\\n",
    "    orderBy(col(\"Event_count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Business Problem 2 - Report generation based on analysis of event data using windowing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = Window. \\\n",
    "    partitionBy(\"EventMonth\", \"Origin\")\n",
    "    rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "events_mdr. \\\n",
    "    filter(\"Event_refunded = 'YES' and Event_status = 'Active'\"). \\\n",
    "    select(concat(\"Year\", \n",
    "                  lpad(\"Month\", 2, \"0\"), \n",
    "                  lpad(\"DayOfMonth\", 2, \"0\")\n",
    "                 ).alias(\"Audit_date\"),\n",
    "           \"Origin\",\n",
    "           \"LoanId\",\n",
    "           \"Event_originator\",\n",
    "           \"Impact_date\",\n",
    "           \"Impact_amount\",\n",
    "           \"Remediation_date\",\n",
    "           \"Payment_date\",\n",
    "           col(\"number_of_impacts\").cast(\"int\").alias(\"multiple_impacts\")\n",
    "          ). \\\n",
    "    withColumn(\"Impact_amount_Min\", min(\"Impact_amount\").over(spec)). \\\n",
    "    withColumn(\"Impact_amount_Max\", max(\"Impact_amount\").over(spec)). \\\n",
    "    withColumn(\"Impact_amount_Sum\", sum(\"Impact_amount\").over(spec)). \\\n",
    "    withColumn(\"Impact_amount_Avg\", avg(\"Impact_amount\").over(spec)). \\\n",
    "    orderBy(\"Event_originator\", \"Origin\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Business Problem 3 - Report generation based on analysis of event data - using ranking and row_number to determine the first\n",
    "## occurrence and multiple occurrence of impacts in case of customers impacted by multiple events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_mdr. \\\n",
    "    filter(\"Event_refunded = 'YES' and Event_status = 'Active'\"). \\\n",
    "    select(concat(\"Year\", \n",
    "                  lpad(\"Month\", 2, \"0\"), \n",
    "                  lpad(\"DayOfMonth\", 2, \"0\")\n",
    "                 ).alias(\"Audit_date\"),\n",
    "           \"Origin\",\n",
    "           \"LoanId\",\n",
    "           \"Event_originator\",\n",
    "           \"Impact_date\",\n",
    "           \"Impact_amount\",\n",
    "           \"Remediation_date\",\n",
    "           \"Payment_date\",\n",
    "           col(\"number_of_impacts\").cast(\"int\").alias(\"multiple_impacts\")\n",
    "          ). \\\n",
    "    withColumn(\"srank\", rank().over(spec)). \\\n",
    "    withColumn(\"drank\", dense_rank().over(spec)). \\\n",
    "    withColumn(\"prank\", round(percent_rank().over(spec), 2)). \\\n",
    "    withColumn(\"rn\", row_number().over(spec)). \\\n",
    "     orderBy(\"Event_originator\", \"Origin\"). \\\n",
    "    write.insertInto(\"event_reporting_XXXX\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processed table are stored in terms of temp table using spark metastore - using Spark.catalog\n",
    "## spark.catalog.createExternalTable\n",
    "## some are stored in existing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data visualization - visualize event reporting data as on number of events per event status per quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "event_reporting_dict = dict(event_reporting_XXXX.collect())\n",
    "refund_status = list(event_reporting_dict.keys())\n",
    "event_count = list(event_reporting_dict.values())\n",
    "\n",
    "plt.plot(refund_status, event_count)\n",
    "plt.xlabel('refund_status')\n",
    "plt.ylabel('event_count')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
